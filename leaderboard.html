---
layout: default
nav_active: leaderboard
title: Same Side Stance Classification - Webis Group
description: Same Side Stance Classification
---

<main class="uk-section uk-section-default">

    <div class="uk-container">

            <h1>Leaderboard</h1>
            <p>We show the best performing model (best accuracy) for each team, sorted by highest accuracy.</p>
<h2> <i>Within</i> Setting Results</h2>

<p>DBS team from LMU exploited the data leakage between the <i>training</i> set and the <i>test</i> set. They were able to predict 99% of the instances. For this reason, we evaluate all submitted predictions using a balanced subset of of the original <i>test</i> set which is not deducible from the <i>training</i> set. </p>
<table id="within-leaderboard" class="leaderboard uk-table  uk-table-hover uk-table-condensed">

    <thead>

        <tr>
            <th>#</th>
            <th>Team</th>
            <th>University</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>Accuracy</th>
        </tr>
    </thead>
    <tbody>
        <tr class="mainrow" id="1">
            <td>1</td>
            <td>ReCAP</td>
            <td>Trier University </td>
            <td>0.85</td>
            <td>0.66</td>
            <td> 0.77</td>
        </tr>
        <tr class="subrow" name="1">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.79</td>
            <td>0.59</td>
            <td>0.71</td>
        </tr>
        <tr class="subrow" name="1">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.90</td>
            <td>0.73</td>
            <td> 0.83</td>
        </tr>
        <tr class="subrow no-align" name="1">
                <td colspan="6"><b>Model overview:</b> BERT (large, uncased, sequence length 512), tuning for 3 epochs.</td>
                </tr>
        <tr id="2">
            <td>2</td>
            <td>ASV</td>
            <td>Leipzig University </td>
            <td>0.79</td>
            <td>0.73</td>
            <td> 0.77</td>
        </tr>
        <tr class="subrow" name="2">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.78</td>
            <td>0.68</td>
            <td>0.75</td>
        </tr>
        <tr class="subrow" name="2">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.80</td>
            <td>0.78</td>
            <td> 0.79</td>
        </tr>
        <tr class="subrow no-align" name="2">
                <td colspan="6"><b>Model overview:</b> BERT (uncased, sequence length 512, tuning for 5 epochs), loss function: sigmoid_binary_crossentrophy.</td>
                </tr>
        <tr id="3">
            <td>3</td>
            <td>IBM Research </td>
            <td>IBM Research </td>
            <td>0.69</td>
            <td>0.59</td>
            <td> 0.66</td>
        </tr>
        <tr class="subrow" name="3">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.64</td>
            <td>0.54</td>
            <td>0.62</td>
        </tr>
        <tr class="subrow" name="3">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.73</td>
            <td>0.63</td>
            <td> 0.70</td>
        </tr>
        <tr class="subrow no-align" name="3">
                <td colspan="6"><b>Model overview:</b> Two BERT models fine-tuned in cascade starting from the vanilla BERT model.</td>
                </tr>
        <tr id="4">
            <td>4</td>
            <td>UKP</td>
            <td>TU Darmstadt </td>
            <td>0.68</td>
            <td>0.52</td>
            <td> 0.64</td>
        </tr>
        <tr class="subrow" name="4">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.63</td>
            <td>0.48</td>
            <td>0.60</td>
        </tr>
        <tr class="subrow" name="4">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.74</td>
            <td>0.56</td>
            <td> 0.68</td>
        </tr>
        <tr class="subrow no-align" name="4">
                <td colspan="6"><b>Model overview:</b> Microsoft's Multi-Task Deep Neural Network mt-dnn. Basis for the mt-dnn is BERT (large). No hyper-parameter tuning, 4 epochs.</td>
                </tr>
        <tr id="5">
            <td>5</td>
            <td>HHU SSSC</td>
            <td>DÃ¼sseldorf University </td>
            <td>0.70</td>
            <td>0.33</td>
            <td> 0.60</td>
        </tr>
        <tr class="subrow" name="5">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.65</td>
            <td>0.32</td>
            <td>0.57</td>
        </tr>
        <tr class="subrow" name="5">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.76</td>
            <td>0.35</td>
            <td> 0.62</td>
        </tr>
        <tr class="subrow no-align" name="5">
                <td colspan="6"><b>Model overview:</b> Manhattan LSTM -- a siamese network -- which measures the similarity of both arguments. Document embeddings via BERT (base, uncased, not fine-tuned, sequence length 512 tokens).</td>
                </tr>
        <tr id="6">
            <td>6</td>
            <td>DBS</td>
            <td>LMU </td>
            <td>0.53</td>
            <td>1.00</td>
            <td> 0.55</td>
        </tr>
        <tr class="subrow" name="6">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.53</td>
            <td>1.00</td>
            <td>0.55</td>
        </tr>
        <tr class="subrow" name="6">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.53</td>
            <td>1.00</td>
            <td> 0.55</td>
        </tr>
        <tr class="subrow no-align" name="6">
                <td colspan="6"><b>Model overview:</b> Bert (base). Arguments organized as graph: edges are weighted with the confidence that arguments agree and confidence that they disagree. If known from training set that the arguments agree or disagree the confidence is 0 and 1 or 1 and 0 accordingly.</td>
                </tr>
        <tr id="7">
            <td>7</td>
            <td>ACQuA</td>
            <td>MLU Halle </td>
            <td>0.53</td>
            <td>0.57</td>
            <td> 0.54</td>
        </tr>
        <tr class="subrow" name="7">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.53</td>
            <td>0.57</td>
            <td>0.53</td>
        </tr>
        <tr class="subrow" name="7">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.54</td>
            <td>0.57</td>
            <td> 0.54</td>
        </tr>
        <tr class="subrow no-align" name="7">
                <td colspan="6"><b>Model overview:</b> Rule-based: same-side classification is considered as a sentiment analysis task. Arguments with negative as well as positive sentiments are on the same side. Vocabulary withf positive and negative words from Minqing Hu and Bing Liu.</td>
                </tr>
        <tr id="8">
            <td>8</td>
            <td>Paderborn University</td>
            <td>Paderborn University </td>
            <td>0.59</td>
            <td>0.19</td>
            <td> 0.53</td>
        </tr>
        <tr class="subrow" name="8">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.62</td>
            <td>0.21</td>
            <td>0.54</td>
        </tr>
        <tr class="subrow" name="8">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.55</td>
            <td>0.17</td>
            <td> 0.52</td>
        </tr>
        <tr class="subrow no-align" name="8">
                <td colspan="6"><b>Model overview:</b> Siamese Neural Network as a benchmark model. Embedding via Flair library.</td>
                </tr>
        <tr id="9">
            <td>9</td>
            <td>sam</td>
            <td>Postdam University </td>
            <td>0.51</td>
            <td>0.58</td>
            <td> 0.51</td>
        </tr>
        <tr class="subrow" name="9">
            <td colspan="3"><i>Abortion</i></td>
            <td>0.56</td>
            <td>0.62</td>
            <td>0.56</td>
        </tr>
        <tr class="subrow" name="9">
            <td colspan="3"><i>Gay Marriage</i></td>
            <td>0.46</td>
            <td>0.54</td>
            <td> 0.45</td>
        </tr>
        <tr class="subrow no-align" name="9">
                <td colspan="6"><b>Model overview:</b> Bidirectional LSTM with 512 hidden units. Embedded sentences are decided via a two-layer MLP.</td>
                </tr>
    </tbody>
</table>
<hr>


<h2> <i>Cross</i> Setting Results</h2>
<p> We conduct the evaluation on two subsets for the <i>Cross</i> domain <i>test</i> set:
    <ul>
            <li><b>Balanced Test Set:</b> balanced subset of the original <i>cross</i> domain <i>test</i> set.</li>
            <li><b>Balanced/No Leakage Test Set:</b> a subset which can not be leaked from the <i>within</i> domain <i>training</i> set. </li>
    </ul>
</p>
<table id="within-leaderboard" class="leaderboard uk-table  uk-table-hover uk-table-condensed">

    <thead>
        <tr>

            <th colspan="3"></th>
            <th colspan="3">Balanced Test Set</th>
            <th colspan="3">Balanced/No Leakage Test Set</th>
        </tr>
        <tr>
            <th>#</th>
            <th>Team</th>
            <th>University</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>Accuracy</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>Accuracy</th>
        </tr>
    </thead>
    <tbody>


        <tr class="mainrow">
            <td>1</td>
            <td>DBS</td>
            <td>LMU </td>
            <td>0.67</td>
            <td>0.53</td>
            <td>0.63</td>
            <td>0.78</td>
            <td>0.61</td>
            <td>0.72</td>
        </tr>
        <tr>
            <td>2</td>
            <td>UKP</td>
            <td>TU Darmstadt </td>
            <td>0.64</td>
            <td>0.59</td>
            <td>0.63</td>
            <td>0.71</td>
            <td>0.63</td>
            <td>0.68</td>
        </tr>
        <tr>
            <td>3</td>
            <td>IBM Research</td>
            <td>IBM Research </td>
            <td>0.62</td>
            <td>0.49</td>
            <td>0.60</td>
            <td>0.74</td>
            <td>0.43</td>
            <td>0.64</td>
        </tr>
        <tr>
            <td>4</td>
            <td>Paderborn University </td>
            <td>Paderborn University </td>
            <td>0.60</td>
            <td>0.38</td>
            <td>0.56</td>
            <td>0.79</td>
            <td>0.33</td>
            <td>0.62</td>
        </tr>
        <tr>
            <td>5</td>
            <td>ReCAP</td>
            <td>Trier University </td>
            <td>0.69</td>
            <td>0.16</td>
            <td>0.54</td>
            <td>1.00</td>
            <td>0.20</td>
            <td>0.60</td>
        </tr>
        <tr class="mainrowsub">
            <td>6</td>
            <td>HHU SSSC</td>
            <td>DÃ¼sseldorf University </td>
            <td>0.72</td>
            <td>0.53</td>
            <td><b>0.66</b></td>
            <td>0.68</td>
            <td>0.37</td>
            <td>0.60</td>
        </tr>
        <tr>
            <td>7</td>
            <td>ACQuA</td>
            <td>MLU Halle </td>
            <td>0.50</td>
            <td>0.57</td>
            <td>0.50</td>
            <td>0.60</td>
            <td>0.54</td>
            <td>0.59</td>
        </tr>
        <tr>
            <td>8</td>
            <td>sam</td>
            <td>Postdam University </td>
            <td>0.51</td>
            <td>0.52</td>
            <td>0.51</td>
            <td>0.57</td>
            <td>0.65</td>
            <td>0.58</td>
        </tr>
        <tr class="dismissed">
            <td>na</td>
            <td>ASV*</td>
            <td>Leipzig University </td>
            <td>0.93</td>
            <td>0.90</td>
            <td>0.92</td>
            <td>0.84</td>
            <td>0.78</td>
            <td>0.82</td>
        </tr>
    </tbody>
</table>
* Dismissed because trained on <i>within</i> training set
<hr>

</div>
</main>